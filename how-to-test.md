‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå Inspur H100 GPU
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ó‡πà‡∏≤‡∏ô
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏Å‡∏±‡∏ö‡∏ó‡∏≤‡∏á Inspur ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ó‡∏≤‡∏á‡∏ú‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Ubuntu ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå ‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠‡∏°‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Virtual GPU ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö NVIDIA A2-16Q ‡∏ó‡∏µ‡πà‡∏™‡∏á‡∏Ç‡∏•‡∏≤ [1]
--------------------------------------------------------------------------------
‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Ubuntu ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SSH)
‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤ NVIDIA H100 80GB GPU ‡∏ó‡∏µ‡πà Inspur ‡πÄ‡∏™‡∏ô‡∏≠‡∏°‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô Physical GPU ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• AI/ML ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Virtual GPU ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô A2-16Q [1-3]
1. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏î‡∏£‡πÄ‡∏ß‡∏≠‡∏£‡πå NVIDIA ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô CUDA:**‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPU, ‡πÑ‡∏î‡∏£‡πÄ‡∏ß‡∏≠‡∏£‡πå, ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô CUDA [4-7]
nvidia-smi  
‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:
‚Ä¢ GPU Model: ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô "NVIDIA H100 80GB" [8, 9] ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
‚Ä¢ CUDA Version: ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö PyTorch ‡πÅ‡∏•‡∏∞‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ AI ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏ä‡πà‡∏ô 12.x ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ)
‚Ä¢ Persistence-M: ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô "On" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ GPU ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
‚Ä¢ Disp.A, Volatile Uncorr. ECC: ‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥ (Off, 0)
‚Ä¢ Memory-Usage: ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á H100 (80GB) [8, 9] ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥ (‡πÄ‡∏ä‡πà‡∏ô 1MiB) ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÄ‡∏ã‡∏™‡πÉ‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà [6]
‚Ä¢ Processes: ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏™‡∏î‡∏á "No running processes found" ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡πÉ‡∏î‡πÜ [7]
2. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á CUDA ‡πÅ‡∏•‡∏∞ PyTorch ‡∏î‡πâ‡∏ß‡∏¢ Python Script:**‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ torch.AcceleratorError: CUDA error: operation not supported ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á Virtual GPU [1, 10] ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå Python ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á CUDA ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO ‡∏ö‡∏ô GPU ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° (‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ):
    ‚ó¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á pip (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á): sudo apt update && sudo apt install python3-pip -y
    ‚ó¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á torch ‡∏û‡∏£‡πâ‡∏≠‡∏° cuda (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô CUDA ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å nvidia-smi):
    ‚ó¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ultralytics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YOLO:
    ‚ó¶ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv8s (‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö):
**Python Script (test_gpu_compatibility.py):**‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏∑‡πà‡∏≠ test_gpu_compatibility.py ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏•‡∏á‡πÑ‡∏õ:
import os  
import torch  
from ultralytics import YOLO  
import numpy as np  
def _detect_optimal_device():  
    """  
    Detect optimal device with virtualized GPU awareness, inspired by source [11].  
    """  
    if not torch.cuda.is_available():  
        print("üî∏ CUDA not available, using CPU")  
        return "cpu"  
    try:  
        # Test basic CUDA operation [11]  
        test_tensor = torch.tensor([1.0]).cuda()  
        test_result = test_tensor * 2  
        torch.cuda.synchronize()  # Force execution  
        # Test more complex operation (similar to what YOLO needs) [11]  
        test_conv = torch.nn.Conv2d(3, 64, 3).cuda()  
        test_input = torch.randn(1, 3, 224, 224).cuda()  
        _ = test_conv(test_input)  
        torch.cuda.synchronize()  
        gpu_name = torch.cuda.get_device_name(0)  
        print(f"‚úÖ GPU validation passed: {gpu_name}")  
        # Special handling for virtualized GPUs [11, 12]  
        if "A2" in gpu_name or "Virtual" in gpu_name or "vGPU" in gpu_name:  
            print("‚ö†Ô∏è  Virtualized GPU detected - using conservative settings")  
            # Even if detected as virtualized, we still try CUDA with awareness  
            return "cuda"  
        return "cuda"  
    except (torch.cuda.OutOfMemoryError, RuntimeError, torch.AcceleratorError) as e:  
        print(f"üî¥ GPU test failed: {e}")  
        print("üîÑ Falling back to CPU for compatibility")  
        return "cpu"  
def _load_yolo_model_safely(model_path, device_to_use):  
    """  
    Load YOLO model with robust error handling, inspired by source [13, 14].  
    """  
    print(f"üîÑ Loading YOLO model: {model_path}")  
    print(f"üéØ Target device: {device_to_use}")  
    try:  
        # Load model first  
        model = YOLO(model_path)  
        # Explicitly set device with error handling [13, 14]  
        if device_to_use == "cuda":  
            try:  
                # Test the model on GPU with a small dummy input  
                dummy_frame = np.zeros((640, 640, 3), dtype=np.uint8)  
                _ = model.predict(dummy_frame, device=device_to_use, verbose=False)  
                print("‚úÖ GPU model validation successful")  
                return model, device_to_use  
            except (torch.AcceleratorError, RuntimeError) as gpu_error:  
                print(f"üî¥ GPU model test failed: {gpu_error}")  
                print("üîÑ Switching to CPU mode for model inference...")  
                device_to_use = "cpu"  
                model = YOLO(model_path)  # Reload for CPU (or just move if it was already loaded)  
                print(f"‚úÖ Model loaded successfully on {device_to_use}")  
                return model, device_to_use  
        else:  
            print(f"‚úÖ Model loaded successfully on {device_to_use}")  
            return model, device_to_use  
    except Exception as e:  
        print(f"‚ùå Critical error loading model: {e}")  
        raise e  
if __name__ == "__main__":  
    print("--- Starting GPU Compatibility Test ---")  
    optimal_device = _detect_optimal_device()  
    print(f"Detected optimal device: {optimal_device}")  
    # Define model path (assuming yolov8s.pt is in /tmp/)  
    model_path = "/tmp/yolov8s.pt"  
    if not os.path.exists(model_path):  
        print(f"‚ùå Error: YOLO model not found at {model_path}. Please download it first.")  
        exit(1)  
    try:  
        model, final_device = _load_yolo_model_safely(model_path, optimal_device)  
        print(f"\nüéâ Test Completed. Model is ready to use on: {final_device}")  
        if final_device == "cpu":  
            print("‚ö†Ô∏è  Warning: Model is running on CPU. This might indicate GPU limitations for ML workloads.")  
    except Exception as e:  
        print(f"\n‚ùå Overall test failed: {e}")  
    print("--- GPU Compatibility Test Finished ---")  
‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå:
python3 test_gpu_compatibility.py  
‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:
‚Ä¢ ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô "‚úÖ GPU validation passed: NVIDIA H100 80GB"
‚Ä¢ ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô "‚ö†Ô∏è Virtualized GPU detected" [11, 12]
‚Ä¢ ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô "üî¥ GPU test failed" ‡∏´‡∏£‡∏∑‡∏≠ "üî¥ GPU model test failed" [13, 14]
‚Ä¢ ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏£‡πÅ‡∏™‡∏î‡∏á "üéâ Test Completed. Model is ready to use on: cuda" [14]
--------------------------------------------------------------------------------
‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Meeting ‡∏Å‡∏±‡∏ö Inspur
‡∏à‡∏≤‡∏Å‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏á‡∏Ç‡∏•‡∏≤ (Face Detection Fusion Model ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á 100+ ‡∏ï‡∏±‡∏ß‡πÅ‡∏•‡∏∞ API requests 500+ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 40 FPS ‡∏ï‡πà‡∏≠ Stream ‡πÉ‡∏ô Original Setup) [15-17] ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î Enterprise-Scale (1,968 ‡∏Å‡∏•‡πâ‡∏≠‡∏á, ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ 31-50 ‡∏Ñ‡∏ô) [18, 19] ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GPU H100/H200 ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å [20-23]
1. ‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥ GPU ‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°:
    ‚ó¶ ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô GPU: NVIDIA H100 80GB ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô Physical GPU 100% ‡πÉ‡∏ä‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà [8, 9]? ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Virtualized GPU ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏≤‡∏ô Compute Capability ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML Workloads ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö A2-16Q ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô Songkhla [1-3]?
    ‚ó¶ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CUDA Compute Capability ‡∏Ç‡∏≠‡∏á H100 ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠‡∏°‡∏≤‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?
    ‚ó¶ ‡∏ó‡∏≤‡∏á Inspur ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á CUDA operations ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Deep Learning frameworks ‡πÄ‡∏ä‡πà‡∏ô PyTorch/YOLO ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? [1, 3]
    ‚ó¶ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô GPU ‡∏ï‡πà‡∏≠‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Inspur ‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1x NVIDIA H100 80GB [9] ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏á‡∏Ç‡∏•‡∏≤ (1,968 ‡∏Å‡∏•‡πâ‡∏≠‡∏á) ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 10-12 H100s ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Recognition Only ‡∏´‡∏£‡∏∑‡∏≠ 14-16 H100s ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face + LPR [20-22] ‡∏ó‡∏≤‡∏á Inspur ‡πÄ‡∏™‡∏ô‡∏≠‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?
2. ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î (Scalability) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏á‡∏Ç‡∏•‡∏≤:
    ‚ó¶ ‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 1,968 ‡∏Å‡∏•‡πâ‡∏≠‡∏á: ‡∏î‡πâ‡∏ß‡∏¢‡∏™‡πÄ‡∏õ‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠‡∏°‡∏≤ (‡∏ã‡∏∂‡πà‡∏á Inspur ‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1x NVIDIA H100 80GB [9]) ‡∏à‡∏∞‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Face Detection + LPR ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á 1,968 ‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà Enterprise-Scale (465-2,000 FPS, 31K-375K API calls/‡∏ß‡∏±‡∏ô) ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ [19, 24]?
    ‚ó¶ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Concurrent Users: ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Concurrent API Requests 500+ ‡πÅ‡∏•‡∏∞ Concurrent Users ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å (‡πÄ‡∏ä‡πà‡∏ô 50 ‡∏Ñ‡∏ô) ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? [15, 18, 19, 25]
    ‚ó¶ ‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏£‡∏∞‡∏ö‡∏ö (Scaling Strategy): Inspur ‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏™‡πÄ‡∏õ‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏¢‡∏π‡∏ô‡∏¥‡∏ï (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Horizontal Scaling) [23, 26-29]?
3. ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î Hardware ‡πÅ‡∏•‡∏∞ Software:
    ‚ó¶ CPU: ‡∏Ç‡∏≠‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏∏‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á Intel Xeon Gold 6438Y (Inspur ‡∏£‡∏∞‡∏ö‡∏∏ 2x Intel Xeon 6438Y) [8, 9]
    ‚ó¶ Memory (RAM): ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤ RAM ‡πÄ‡∏õ‡πá‡∏ô ECC DDR5 ‡∏Ç‡∏ô‡∏≤‡∏î 512GB (16x 32GB) ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà [9, 30]?
    ‚ó¶ Storage: * ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á SSD (2x 3.84TB U.2 SSD) ‡πÅ‡∏•‡∏∞ HDD (6x 20TB SATA Enterprise HDD) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏ô‡∏ü‡∏¥‡∏Å‡∏π‡πÄ‡∏£‡∏ä‡∏±‡∏ô RAID (RAID 9560-16i) [8, 9, 30, 31] * ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£ Storage ‡πÄ‡∏õ‡πá‡∏ô Tiered Storage (Hot, Warm, Cold) ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 17.7TB/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Recognition Only ‡∏´‡∏£‡∏∑‡∏≠ 30-50TB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Enterprise Scale [19, 20, 32]?
    ‚ó¶ Network (NIC): ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏µ 2x 10Gbps NIC [9] ‡πÅ‡∏•‡∏∞‡∏à‡∏∞‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Network Bandwidth ‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏á‡∏Ç‡∏•‡∏≤ (Edge Layer ~10 Gbps, Aggregation Layer 15 Gbps, Core Layer 20 Gbps) ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ [22, 23, 33, 34]?
    ‚ó¶ ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå: * Ubuntu ‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏î? * ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á NVIDIA Driver ‡πÅ‡∏•‡∏∞ CUDA Toolkit ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á? * ‡∏°‡∏µ‡∏Å‡∏≤‡∏£ Pre-install Deep Learning frameworks (‡πÄ‡∏ä‡πà‡∏ô PyTorch, TensorFlow) ‡πÅ‡∏•‡∏∞‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ YOLO ‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? ‡∏´‡∏≤‡∏Å‡∏°‡∏µ ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏î?
4. ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (Reliability & Support):
    ‚ó¶ Fault Tolerance/Redundancy: Inspur ‡∏°‡∏µ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏î‡πâ‡∏≤‡∏ô N+1 ‡∏´‡∏£‡∏∑‡∏≠ N+2 Redundancy ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Workloads ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏≠‡∏á Hardware (‡πÄ‡∏ä‡πà‡∏ô GPU, PSU, Storage) [27, 35, 36]?
    ‚ó¶ ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô: Inspur ‡∏°‡∏µ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤ (SLA, 24/7 support) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU ‡πÅ‡∏•‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ [37]? ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏î‡∏£‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå?
    ‚ó¶ Case Study: Inspur ‡∏°‡∏µ‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏´‡∏£‡∏∑‡∏≠ Reference Sites ‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå H100 ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ AI/ML ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏π‡∏á‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Å‡∏•‡πâ‡∏≠‡∏á CCTV ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ Songkhla CCTV Integration Project ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?
--------------------------------------------------------------------------------
‡∏´‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏£‡∏≤‡∏ö‡∏£‡∏∑‡πà‡∏ô‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏£‡∏±‡∏ö.